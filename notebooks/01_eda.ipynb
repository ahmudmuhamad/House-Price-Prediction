{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e45386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"../data/raw/train.csv\")\n",
    "eval_df = pd.read_csv(r\"../data/raw/eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.city_full.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "duplicated_rows = train_df[train_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated(subset=train_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98acd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicates\n",
    "train_df = train_df.drop_duplicates(subset=train_df.columns.difference(['date', 'year']), keep=False)\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated(subset=train_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96afec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_df.shape)\n",
    "\n",
    "\n",
    "duplicated_rows = eval_df[eval_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = eval_df[eval_df.duplicated(subset=eval_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090da54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicates\n",
    "eval_df = eval_df.drop_duplicates(subset=eval_df.columns.difference(['date', 'year']), keep=False)\n",
    "\n",
    "print(eval_df.shape)\n",
    "\n",
    "\n",
    "duplicated_rows = eval_df[eval_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = eval_df[eval_df.duplicated(subset=eval_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d856b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('city_full', axis=1, inplace=True)\n",
    "eval_df.drop('city_full', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e646a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_per_city(df, col):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # Group by city so we compare apples to apples\n",
    "    for city, group in df.groupby('city'):\n",
    "        Q1 = group[col].quantile(0.25)\n",
    "        Q3 = group[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_limit = Q1 - 1.5 * IQR\n",
    "        upper_limit = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Find rows in THIS city that are outliers\n",
    "        local_outliers = group[(group[col] < lower_limit) | (group[col] > upper_limit)]\n",
    "        outlier_indices.extend(local_outliers.index)\n",
    "        \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "# usage\n",
    "bad_indices = find_outliers_per_city(train_df, 'median_sale_price')\n",
    "print(f\"Found {len(bad_indices)} rows that are outliers relative to their specific city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of house prices across the dataset \n",
    "df = train_df\n",
    "sns.set_theme(style=\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.histplot(df[\"price\"].dropna(), bins=60, kde=True, color=sns.color_palette(\"rocket_r\", 1)[0], ax=ax)\n",
    "median_price = df[\"price\"].median()\n",
    "ax.axvline(median_price, ls=\"--\", lw=1.2, color=\"black\")\n",
    "ax.set_xlabel(\"Price ($)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "sns.despine(trim=True)\n",
    "ax.grid(False)\n",
    "ax.ticklabel_format(axis=\"x\", style=\"plain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ac601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(r\"../data/interim/train_1.csv\", index=False)\n",
    "eval_df.to_csv(r\"../data/interim/eval_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
