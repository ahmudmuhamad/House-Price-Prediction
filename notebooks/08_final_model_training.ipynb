{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP\n",
    "# ==========================================\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8000\")\n",
    "mlflow.set_experiment(\"Experiment Tracking - House Price Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Data\n",
    "\n",
    "train_df = pd.read_csv(r\"../data/processed/train.csv\")\n",
    "eval_df = pd.read_csv(r\"../data/processed/eval.csv\")\n",
    "holdout_df = pd.read_csv(r\"../data/processed/holdout.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9930be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Selection\n",
    "target = \"price\"\n",
    "# We drop the target AND the raw identifiers (date, text columns)\n",
    "# We keep 'year' out of training to avoid overfitting to specific timelines\n",
    "drop_cols = [target, \"date\", \"year\", \"city\", \"state_id\", \"zipcode\"]\n",
    "\n",
    "# Prepare X and y (Filtering for numbers only)\n",
    "X_train = train_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_eval = eval_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "y_eval = eval_df[target]\n",
    "\n",
    "X_test = holdout_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "y_test = holdout_df[target]\n",
    "\n",
    "# CRITICAL: For final production model, we learn from ALL history (Train + Eval)\n",
    "X_full_train = pd.concat([X_train, X_eval]).reset_index(drop=True)\n",
    "y_full_train = pd.concat([y_train, y_eval]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Training on {len(X_full_train)} rows (Train+Eval).\")\n",
    "print(f\"Testing on {len(X_test)} rows (Holdout).\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. THE CHAMPION PARAMETERS (Restored)\n",
    "# ==========================================\n",
    "best_params = {\n",
    "    'n_estimators': 766,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.056659883160228804,\n",
    "    'subsample': 0.6028207008279798,\n",
    "    'colsample_bytree': 0.8388551767066131,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_alpha': 2.716993750938802e-05,\n",
    "    'reg_lambda': 8.658796440498847,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': \"hist\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. TRAIN & LOG CHAMPION\n",
    "# ==========================================\n",
    "with mlflow.start_run(run_name=\"Champion_XGBoost_Final\"):\n",
    "    \n",
    "    print(\"ðŸš€ Training Final Production Model...\")\n",
    "    \n",
    "    # Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('regressor', XGBRegressor(**best_params))\n",
    "    ])\n",
    "    \n",
    "    # Log-Transform Wrapper\n",
    "    final_model = TransformedTargetRegressor(\n",
    "        regressor=pipeline,\n",
    "        func=np.log1p,\n",
    "        inverse_func=np.expm1\n",
    "    )\n",
    "    \n",
    "    # Train on Full History\n",
    "    final_model.fit(X_full_train, y_full_train)\n",
    "    \n",
    "    # Evaluate on Holdout (Final Test)\n",
    "    preds = final_model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š FINAL HOLDOUT SCORES:\")\n",
    "    print(f\"   RMSE: ${rmse:,.0f}\")\n",
    "    print(f\"   MAE:  ${mae:,.0f}\")\n",
    "    print(f\"   R2:   {r2:.4f}\")\n",
    "    \n",
    "    # Log to MLflow\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"holdout_rmse\", rmse)\n",
    "    mlflow.log_metric(\"holdout_r2\", r2)\n",
    "    \n",
    "    # Save Model\n",
    "    signature = infer_signature(X_test, preds)\n",
    "    mlflow.sklearn.log_model(final_model, \"champion_model\", signature=signature)\n",
    "    \n",
    "    print(\"\\nâœ… Champion Model Saved to MLflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
